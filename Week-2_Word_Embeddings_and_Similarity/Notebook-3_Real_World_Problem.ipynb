{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V5E1","authorship_tag":"ABX9TyNh/p1DXCGlDb+pn7QPw70w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["# **Advanced Word Embedding Benchmarking on Noisy Real-World Corpus**\n","- ### **Multi-Class Newsgroups Dataset**"],"metadata":{"id":"kBCM-KCjjoz4"}},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"nyE8-IS4W_SM","executionInfo":{"status":"ok","timestamp":1772122519208,"user_tz":-330,"elapsed":2361,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"eeb7e854-ce25-4abb-8e50-70ac5c1d78ce"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (23.0.1)\n","Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n","Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\n","Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n","Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.12.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2026.1.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n","Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n","Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.24.0)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.24.0)\n","Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n","Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (14.3.2)\n","Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.1.2)\n"]}]},{"cell_type":"code","source":["import spacy\n","!python -m spacy download en_core_web_sm\n","nlp = spacy.load('en_core_web_sm')\n","from collections import Counter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-t37g_7eMCK","executionInfo":{"status":"ok","timestamp":1772122533957,"user_tz":-330,"elapsed":11362,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"f2905411-9630-4e3a-ca8b-a35ebd771f6c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m162.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"SetFit/20_newsgroups\")\n","\n","X_train = dataset['train']['text']\n","y_train = dataset['train']['label']\n","X_test = dataset['test']['text']\n","y_test = dataset['test']['label']\n","\n","len(X_train), len(y_train), len(X_test), len(y_test)\n","len(set(y_train)), len(set(y_test))\n","print(set(y_train))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwGgamYoExHx","executionInfo":{"status":"ok","timestamp":1772123985041,"user_tz":-330,"elapsed":1081,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"0f38fd6d-49a4-45b4-9679-4fdb0e5ed7ba"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]},{"output_type":"stream","name":"stdout","text":["{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"8f6f1257","executionInfo":{"status":"ok","timestamp":1772122541104,"user_tz":-330,"elapsed":221,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"f28c8333-32c0-489e-8a9b-014fee5a7425"},"source":["from collections import Counter\n","\n","print(\"Train set class distribution:\")\n","for label, count in sorted(Counter(y_train).items()):\n","    print(f\"Class {label}: {count} samples\")\n","\n","print(\"\\nTest set class distribution:\")\n","for label, count in sorted(Counter(y_test).items()):\n","    print(f\"Class {label}: {count} samples\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set class distribution:\n","Class 0: 480 samples\n","Class 1: 584 samples\n","Class 2: 591 samples\n","Class 3: 590 samples\n","Class 4: 578 samples\n","Class 5: 593 samples\n","Class 6: 585 samples\n","Class 7: 594 samples\n","Class 8: 598 samples\n","Class 9: 597 samples\n","Class 10: 600 samples\n","Class 11: 595 samples\n","Class 12: 591 samples\n","Class 13: 594 samples\n","Class 14: 593 samples\n","Class 15: 599 samples\n","Class 16: 546 samples\n","Class 17: 564 samples\n","Class 18: 465 samples\n","Class 19: 377 samples\n","\n","Test set class distribution:\n","Class 0: 480 samples\n","Class 1: 584 samples\n","Class 2: 591 samples\n","Class 3: 590 samples\n","Class 4: 578 samples\n","Class 5: 593 samples\n","Class 6: 585 samples\n","Class 7: 594 samples\n","Class 8: 598 samples\n","Class 9: 597 samples\n","Class 10: 600 samples\n","Class 11: 595 samples\n","Class 12: 591 samples\n","Class 13: 594 samples\n","Class 14: 593 samples\n","Class 15: 599 samples\n","Class 16: 546 samples\n","Class 17: 564 samples\n","Class 18: 465 samples\n","Class 19: 377 samples\n"]}]},{"cell_type":"markdown","source":["> ## Step 1 — Preprocessing\n","\n","\n"],"metadata":{"id":"aMXv_Kfhkcmk"}},{"cell_type":"code","source":["def preprocessing(text,\n","                  lowercase = True,\n","                  remove_stopword = False,\n","                  remove_punct = False,\n","                  lemmatized = False,\n","                  remove_metadata = False\n","                  ):\n","   preprocessed_text = []\n","   freq = Counter()\n","\n","   current_texts = text\n","   if remove_metadata:\n","         # Assuming 'text' is an iterable of strings if remove_metadata is True\n","         current_texts = [t.split(\"\\n\\n\", 1)[-1] for t in text]\n","\n","   docs = nlp.pipe(current_texts, batch_size=32) # Corrected indentation\n","\n","   for doc in docs:\n","     doc_tokens = [] # Renamed to avoid shadowing\n","     for token in doc:\n","\n","       if remove_stopword and token.is_stop:\n","         continue\n","       if remove_punct and token.is_punct:\n","         continue\n","\n","       if not token.is_alpha:\n","         continue\n","\n","       word = token.lemma_ if lemmatized else token.text # Corrected 'word' to 'token'\n","\n","       if lowercase:\n","         word = word.lower()\n","\n","       doc_tokens.append(word)\n","       freq[word] += 1            # Moved inside the token loop for correct frequency counting\n","\n","     preprocessed_text.append(doc_tokens)\n","\n","   return preprocessed_text, freq"],"metadata":{"id":"nlpA4BDgW9lZ","executionInfo":{"status":"ok","timestamp":1772122544257,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["X, frequency = preprocessing(X_train, lowercase=True, remove_stopword=True, remove_punct=True, lemmatized=True, remove_metadata=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"collapsed":true,"id":"nJ6QnqUOsSSh","executionInfo":{"status":"error","timestamp":1772122875968,"user_tz":-330,"elapsed":328625,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"9bffbba4-ed44-430f-ed3e-a24edf1f2ca5"},"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'x' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1049/598646556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_stopword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_punct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlemmatized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"]}]},{"cell_type":"code","source":["print(X[0:5])\n","print(frequency[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGh1JK7Hwglb","executionInfo":{"status":"ok","timestamp":1772122936038,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"abb7a81c-12e1-4fdc-d7a7-49ac9f19ce33"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[['wonder', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'small', 'addition', 'bumper', 'separate', 'rest', 'body', 'know', 'tellme', 'model', 'engine', 'spec', 'year', 'production', 'car', 'history', 'info', 'funky', 'look', 'car', 'e', 'mail'], ['summarize', 'day', 'add', 'network', 'knowledge', 'base', 'clock', 'upgrade', 'answer', 'poll', 'thank'], ['look', 'pick', 'powerbook', 'maybe', 'bunch', 'question', 'hopefully', 'somebody', 'answer', 'anybody', 'know', 'dirt', 'round', 'powerbook', 'introduction', 'expect', 'hear', 'suppose', 'appearence', 'summer', 'hear', 'anymore', 'access', 'macleak', 'wonder', 'anybody', 'info', 'anybody', 'hear', 'rumor', 'price', 'drop', 'powerbook', 'line', 'like', 'one', 'duo', 'go', 'recently', 'impression', 'display', 'probably', 'swing', 'get', 'disk', 'feel', 'well', 'display', 'yea', 'look', 'great', 'store', 'wow', 'good', 'solicit', 'opinion', 'people', 'use', 'day', 'day', 'worth', 'take', 'disk', 'size', 'money', 'hit', 'active', 'display', 'realize', 'real', 'subjective', 'question', 'play', 'machine', 'computer', 'store', 'breifly', 'figure', 'opinion', 'somebody', 'actually', 'use', 'machine', 'daily', 'prove', 'helpful', 'hellcat', 'perform', 'thank', 'bunch', 'advance', 'info', 'email', 'post', 'summary', 'news', 'reading', 'time', 'premium', 'final', 'corner', 'tom', 'willis', 'purdue', 'electrical', 'engineering'], ['weitek', 'address', 'phone', 'number', 'like', 'information', 'chip'], ['understanding', 'expect', 'error', 'basically', 'know', 'bug', 'warning', 'system', 'software', 'thing', 'check', 'right', 'value', 'set', 'till', 'launch', 'suchlike', 'fix', 'code', 'possibly', 'introduce', 'new', 'bug', 'tell', 'crew', 'ok', 'warning', 'liftoff', 'ignore']]\n","0\n"]}]},{"cell_type":"markdown","source":["> ## Step 2 — Second Pass: Remove Rare Words"],"metadata":{"id":"ZfBzsEnBkLbP"}},{"cell_type":"code","source":["def remove_rare_words(tokenized_docs, freq_dict, min_threshold=5):\n","\n","    filtered_docs = []\n","\n","    for doc in tokenized_docs:\n","        filtered_doc = [\n","            word for word in doc\n","            if freq_dict[word] >= min_threshold\n","        ]\n","        filtered_docs.append(filtered_doc)\n","\n","    return filtered_docs"],"metadata":{"id":"D3fQsZquehfz","executionInfo":{"status":"ok","timestamp":1772122946466,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["X_final = remove_rare_words(X, frequency, min_threshold=5)\n","print(X_final[0:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEWwdOVdsvxC","executionInfo":{"status":"ok","timestamp":1772122949182,"user_tz":-330,"elapsed":107,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"d49efcdb-c876-4511-f8ed-5462e4f6f91f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[['wonder', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'door', 'small', 'addition', 'bumper', 'separate', 'rest', 'body', 'know', 'model', 'engine', 'spec', 'year', 'production', 'car', 'history', 'info', 'funky', 'look', 'car', 'e', 'mail'], ['summarize', 'day', 'add', 'network', 'knowledge', 'base', 'clock', 'upgrade', 'answer', 'poll', 'thank'], ['look', 'pick', 'powerbook', 'maybe', 'bunch', 'question', 'hopefully', 'somebody', 'answer', 'anybody', 'know', 'dirt', 'round', 'powerbook', 'introduction', 'expect', 'hear', 'suppose', 'summer', 'hear', 'anymore', 'access', 'wonder', 'anybody', 'info', 'anybody', 'hear', 'rumor', 'price', 'drop', 'powerbook', 'line', 'like', 'one', 'duo', 'go', 'recently', 'impression', 'display', 'probably', 'swing', 'get', 'disk', 'feel', 'well', 'display', 'yea', 'look', 'great', 'store', 'wow', 'good', 'solicit', 'opinion', 'people', 'use', 'day', 'day', 'worth', 'take', 'disk', 'size', 'money', 'hit', 'active', 'display', 'realize', 'real', 'subjective', 'question', 'play', 'machine', 'computer', 'store', 'figure', 'opinion', 'somebody', 'actually', 'use', 'machine', 'daily', 'prove', 'helpful', 'perform', 'thank', 'bunch', 'advance', 'info', 'email', 'post', 'summary', 'news', 'reading', 'time', 'premium', 'final', 'corner', 'tom', 'willis', 'purdue', 'electrical', 'engineering'], ['weitek', 'address', 'phone', 'number', 'like', 'information', 'chip'], ['understanding', 'expect', 'error', 'basically', 'know', 'bug', 'warning', 'system', 'software', 'thing', 'check', 'right', 'value', 'set', 'till', 'launch', 'fix', 'code', 'possibly', 'introduce', 'new', 'bug', 'tell', 'crew', 'ok', 'warning', 'liftoff', 'ignore'], ['course', 'term', 'define', 'bill', 'doubt', 'use', 'term', 'quote', 'allegedly', 'read', 'article', 'present', 'argument', 'weapon', 'mass', 'destruction', 'commonly', 'understand', 'switch', 'topic', 'point', 'evidently', 'weapon', 'allow', 'later', 'analysis', 'give', 'understanding', 'consider', 'class'], ['thank', 'sure', 'glad', 'accidentally', 'hit', 'rn', 'instead', 'rm', 'try', 'delete', 'file', 'september', 'hmmm', 'news'], ['controler', 'chip', 'range', 's', 'right', 'scsi', 'controller', 'chip', 's', 's', 'burst', 'bit', 'note', 'increase', 'speed', 'mac', 'quadra', 'use', 'version', 'exist', 'pc', 'use', 'set', 'bit', 'mode', 's', 's', 'burst', 'bit', 'wide', 'fast', 'mode', 's', 's', 'burst', 'bit', 'wide', 'fast', 's', 's', 'burst', 'datum', 'scsi', 'twice', 'fast', 'esdi', 'correct', 'controller', 'chip', 'reach', 's', 'fast', 'ide', 'scsi', 'fact', 'post', 'newsgroup', 'mac', 'ibm', 'info', 'sheet', 'available', 'ftp', 'info', 'mac', 'report', 'mac', 'ibm', 'problem', 'mac', 'ibm', 'pc', 'scsi', 'document', 'quadra', 'chip', 'apple', 'salesperson', 'say', 'use', 'fast', 'chip', 's', 's', 'burst', 's', 'maximum', 'synchronous', 'quadra', 'use', 'scsi', 'mac', 'ibm', 'interface', 'think', 'maybe', 'interface', 'drive', 'machine', 'controller', 'chip', 'bit', 'mode', 'true'], ['thanx'], ['board', 'year', 'work', 'licensing', 'problem', 'technologies', 'owner', 'board', 'compression', 'technology', 'write', 'memory', 'lose', 'reference', 'correct', 'wrong', 'board', 'problem', 'file', 'icon', 'lose', 'hard', 'board', 'fault', 'decompress', 'troubled', 'file', 'board', 'icon', 'usually', 'reappear', 'mention', 'licensing', 'problem', 'freeware', 'expansion', 'utility', 'dd', 'expand', 'decompress', 'board', 'compress', 'file', 'board', 'instal', 'product', 'unlikely', 'hole', 'relate', 'board', 'fix', 'sad', 'make', 'reluctant', 'buy', 'product', 'hey', 'competition']]\n"]}]},{"cell_type":"markdown","source":["> ## Step 3 — Train All Embedding Models"],"metadata":{"id":"CmmUOSBRlNP7"}},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"-Wmo7EKrHB3g","executionInfo":{"status":"ok","timestamp":1772122959051,"user_tz":-330,"elapsed":2951,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"6c7c7f70-b679-4bbc-e613-0277608da043"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n","Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n","Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gensim\n","Successfully installed gensim-4.4.0\n"]}]},{"cell_type":"code","source":["from gensim.models import Word2Vec, FastText\n","import os\n","\n","def embedding_train(text, model_name):\n","\n","  os.makedirs('models', exist_ok=True) # Ensure 'models' directory exists\n","  save_path = f'models/{model_name}'\n","  model = None # Initialize a variable to hold the trained model\n","\n","  if model_name == 'word2vec-cbow':\n","    model = Word2Vec(\n","        sentences = text,\n","        window = 5,\n","        vector_size=300,\n","        min_count=5,\n","        sg=0,                      # 0 = cbow\n","        epochs=20\n","    )\n","    model.save(save_path)\n","\n","  elif model_name == 'word2vec-sg': # Corrected indentation\n","    model = Word2Vec(\n","          sentences = text,\n","          window = 5,\n","          vector_size = 300,\n","          min_count = 5,\n","          sg = 1,                  # 1 = skipgram\n","          epochs = 20\n","      )\n","    model.save(save_path)\n","\n","  elif model_name == 'fasttext': # Corrected indentation\n","    model = FastText(\n","            sentences = text,\n","            window = 5,\n","            vector_size = 100,\n","            min_n = 3,\n","            max_n = 5,\n","            min_count = 5,\n","            epochs = 10,\n","            sg = 1\n","\n","        )\n","    model.save(save_path)\n","\n","  else:\n","      raise ValueError(\"Invalid model name\")\n","\n","  return model # Return only the trained model"],"metadata":{"id":"igumgAVvlPmZ","executionInfo":{"status":"ok","timestamp":1772122964581,"user_tz":-330,"elapsed":2951,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["embedding_train(X_final, model_name= 'word2vec-cbow')\n","embedding_train(X_final, model_name='word2vec-sg')\n","embedding_train(X_final, model_name='fasttext')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PuF0uLAjVSO6","executionInfo":{"status":"ok","timestamp":1772123061645,"user_tz":-330,"elapsed":92565,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"b64fdfca-ccaa-4d99-c018-62949d201c6d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<gensim.models.fasttext.FastText at 0x7833c5a063f0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["> ## Step 4 - Load and Test Models"],"metadata":{"id":"6KlJx3r4VS_i"}},{"cell_type":"markdown","source":["> ### 1. Model Loader"],"metadata":{"id":"hUhPcuLEY3vk"}},{"cell_type":"code","source":["import gensim.downloader as api\n","\n","def load_model(model_name):\n","\n","    if model_name == \"word2vec-cbow\":\n","        model = Word2Vec.load(\"/content/models/word2vec-cbow\")\n","        return model.wv\n","\n","    elif model_name == \"word2vec-sg\":\n","        model = Word2Vec.load(\"/content/models/word2vec-sg\") # Corrected filename from word2vec_sg to word2vec-sg\n","        return model.wv\n","\n","    elif model_name == \"fasttext\":\n","        model = FastText.load(\"/content/models/fasttext\")\n","        return model.wv\n","\n","    elif model_name == \"glove\":\n","        model = api.load(\"glove-wiki-gigaword-100\")\n","        return model\n","\n","    else:\n","        raise ValueError(\"Invalid model name\")\n","\n","    return model"],"metadata":{"id":"AG3BbQbYY3Gc","executionInfo":{"status":"ok","timestamp":1772123107775,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["cbow = load_model(model_name='word2vec-cbow')\n","sg = load_model(model_name='word2vec-sg')\n","fasttext = load_model(model_name='fasttext')"],"metadata":{"id":"AqlC8_ZTMNfB","executionInfo":{"status":"ok","timestamp":1772123111506,"user_tz":-330,"elapsed":707,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["> ### 2. Word Similarity\n","- Cosine similarity\n","- Neighborhood consistency"],"metadata":{"id":"FHhFpADOVi8T"}},{"cell_type":"code","source":["def word_similarity(wv):\n","\n","    pairs = [\n","    (\"computer\", \"hardware\"),\n","    (\"windows\", \"microsoft\"),\n","    (\"baseball\", \"pitcher\"),\n","    (\"religion\", \"christian\"),\n","    (\"space\", \"nasa\")\n","]\n","\n","    for w1, w2 in pairs:\n","        if w1 in wv and w2 in wv:\n","            print(f\"{w1} ~ {w2} :\", wv.similarity(w1, w2))\n","        else:\n","            print(f\"{w1} or {w2} not found in the vocabulary\")"],"metadata":{"id":"yT34fShNVhqD","executionInfo":{"status":"ok","timestamp":1772123116002,"user_tz":-330,"elapsed":2,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["word_similarity(cbow)\n","word_similarity(sg)\n","word_similarity(fasttext)\n","\n","\n","print(len(cbow.index_to_key))\n","print(len(sg.index_to_key))\n","print(len(fasttext.index_to_key))\n","\n","\n","print(\"religion\" in cbow)\n","print(\"religion\" in sg)\n","print(\"religion\" in fasttext)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXrjbJy8OtQx","executionInfo":{"status":"ok","timestamp":1772123118173,"user_tz":-330,"elapsed":12,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"b9150c4d-58d4-4f22-8f1c-349b4f459254"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["computer ~ hardware : 0.42193297\n","windows ~ microsoft : 0.6925483\n","baseball ~ pitcher : 0.67440003\n","religion ~ christian : 0.6286671\n","space ~ nasa : 0.48824137\n","computer ~ hardware : 0.24264935\n","windows ~ microsoft : 0.57211584\n","baseball ~ pitcher : 0.41234586\n","religion ~ christian : 0.3764064\n","space ~ nasa : 0.40271625\n","computer ~ hardware : 0.4647874\n","windows ~ microsoft : 0.7184713\n","baseball ~ pitcher : 0.64109296\n","religion ~ christian : 0.6735169\n","space ~ nasa : 0.52174824\n","13455\n","13455\n","13455\n","True\n","True\n","True\n"]}]},{"cell_type":"markdown","source":["> ## 3. Analogy Test"],"metadata":{"id":"dEVyA4tDZ0Ef"}},{"cell_type":"code","source":["def analogy_test(wv):\n","\n","    pairs = [\n","    (\"baseball\", \"pitcher\", \"hockey\"),\n","    (\"windows\", \"microsoft\", \"linux\"),\n","    (\"space\", \"nasa\", \"earth\")\n","]\n","\n","    for a, b, c in pairs:\n","\n","        if all(word in wv for word in [a, b, c]):\n","\n","            result = wv.most_similar(\n","                positive=[b, c],   # b + c\n","                negative=[a],      # - a\n","                topn=1\n","            )\n","\n","            print(f\"{b} - {a} + {c} → {result[0][0]} (score={result[0][1]:.4f})\")\n","\n","        else:\n","            print(f\"Missing words in vocab: {a}, {b}, {c}\")"],"metadata":{"id":"SJU3_2lIZ29N","executionInfo":{"status":"ok","timestamp":1772123130467,"user_tz":-330,"elapsed":60,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["analogy_test(cbow)\n","analogy_test(sg)\n","analogy_test(fasttext)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSGYF2FyaHTE","executionInfo":{"status":"ok","timestamp":1772123134083,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"d4e5b950-96c3-4721-f8cd-b6cf761136d4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["pitcher - baseball + hockey → mvp (score=0.7014)\n","microsoft - windows + linux → isc (score=0.6568)\n","nasa - space + earth → mission (score=0.5621)\n","pitcher - baseball + hockey → tournament (score=0.4490)\n","microsoft - windows + linux → isc (score=0.4385)\n","nasa - space + earth → shafer (score=0.3411)\n","pitcher - baseball + hockey → gilkey (score=0.6812)\n","microsoft - windows + linux → ux (score=0.7030)\n","nasa - space + earth → earthly (score=0.6442)\n"]}]},{"cell_type":"markdown","source":["> ### 4. OOV Testing"],"metadata":{"id":"Ouc3PPoIa4As"}},{"cell_type":"code","source":["def oov_test(wv, model_name):\n","\n","    test_words = [\n","        \"computering\",\n","        \"religiosity\",\n","        \"baseballic\",\n","        \"xyzrandomword\"\n","    ]\n","\n","    print(f\"\\nOOV Testing for {model_name}\")\n","\n","    for word in test_words:\n","        if word in wv:\n","            print(word, \"-> Exists\")\n","        else:\n","            print(word, \"-> OOV\")\n"],"metadata":{"id":"Zh2O9fhWa_kL","executionInfo":{"status":"ok","timestamp":1772123142647,"user_tz":-330,"elapsed":1,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["oov_test(cbow, \"word2vec-cbow\")\n","oov_test(sg, \"word2vec-sg\")\n","oov_test(fasttext, \"fasttext\")\n","\n","print(len(cbow.index_to_key))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBLSPkRObIEF","executionInfo":{"status":"ok","timestamp":1772123144978,"user_tz":-330,"elapsed":6,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"f6f43167-baf1-467a-f889-ba10119146a9"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","OOV Testing for word2vec-cbow\n","computering -> OOV\n","religiosity -> OOV\n","baseballic -> OOV\n","xyzrandomword -> OOV\n","\n","OOV Testing for word2vec-sg\n","computering -> OOV\n","religiosity -> OOV\n","baseballic -> OOV\n","xyzrandomword -> OOV\n","\n","OOV Testing for fasttext\n","computering -> Exists\n","religiosity -> Exists\n","baseballic -> Exists\n","xyzrandomword -> Exists\n","13455\n"]}]},{"cell_type":"markdown","source":["> ### 5. Downstream Classification\n","- Step 1 : Document Embedding\n","- Step 2 : Build the Matrix"],"metadata":{"id":"GD_p3DdScFGM"}},{"cell_type":"code","source":["# document embedding\n","import numpy as np\n","\n","def document_vector(doc, wv, dim):\n","\n","    vectors = [wv[word] for word in doc if word in wv]\n","\n","    if len(vectors) == 0:\n","        return np.zeros(dim)\n","\n","    return np.mean(vectors, axis=0)\n","\n","# bulid the matrix\n","def build_features(tokenized_docs, labels, wv, dim):\n","\n","    X = []\n","    y = labels\n","\n","    for doc in tokenized_docs:\n","        vec = document_vector(doc, wv, dim)\n","        X.append(vec)\n","\n","    return np.array(X), np.array(y)"],"metadata":{"id":"lWNfn941cYUt","executionInfo":{"status":"ok","timestamp":1772124003240,"user_tz":-330,"elapsed":3,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["X_train_features, y_train_labels_for_clf = build_features(X_final, y_train, cbow, 300)\n","print(X_train_features[0:10], y_train_labels_for_clf[0:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S6NXxcg5cKrJ","executionInfo":{"status":"ok","timestamp":1772124008915,"user_tz":-330,"elapsed":1234,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"19d7ad1e-918f-4b3e-c488-02b3f85c96a2"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.43881485 -0.19834305 -0.24444368 ...  0.02988239 -0.43765441\n","  -0.05863502]\n"," [-0.31540549 -0.03059752 -0.06693599 ...  0.25572109 -0.01122992\n","  -0.1991403 ]\n"," [-0.12215306  0.02826146 -0.07954741 ...  0.14835274 -0.22857264\n","  -0.08701497]\n"," ...\n"," [ 0.16630875  0.22080763  0.12913539 ...  0.62115443 -0.19018491\n","  -0.26410386]\n"," [ 0.38515699  0.02185475 -0.48475188 ... -0.3693566   0.42197284\n","   0.67591834]\n"," [-0.13825397  0.33182997 -0.02857118 ...  0.01054335 -0.12259699\n","  -0.27810469]] [ 7  4  4  1 14 16 13  3  2  4]\n"]}]},{"cell_type":"markdown","source":["> ### Train the Classifier\n","- lr, svm\n","- Metric: accuracy, macro f1"],"metadata":{"id":"WRjhkiUrdG7D"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","def downstream_classification(X_features, y_features):\n","\n","  X_train, X_test, y_train, y_test = train_test_split(\n","    X_features,\n","    y_features,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=y_train_labels_for_clf   # Important for 20 classes\n",")\n","\n","  clf = LogisticRegression(\n","    max_iter=2000,\n","    multi_class='multinomial',\n","    solver='lbfgs'\n",")\n","\n","  clf.fit(X_train, y_train)\n","\n","  preds = clf.predict(X_test)\n","\n","  acc = accuracy_score(y_test, preds)\n","  f1 = f1_score(y_test, preds, average=\"macro\")\n","\n","  print(\"Accuracy:\", acc)\n","  print(\"Macro F1:\", f1)\n","\n","  return acc, f1"],"metadata":{"id":"VtcR7SpedUDy","executionInfo":{"status":"ok","timestamp":1772124555564,"user_tz":-330,"elapsed":13,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["print(X_train_features.shape)\n","print(y_train_labels_for_clf.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yxw1wqXg18BT","executionInfo":{"status":"ok","timestamp":1772124359183,"user_tz":-330,"elapsed":54,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"05598332-7f48-42bd-b821-266ee009398f"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["(11314, 300)\n","(11314,)\n"]}]},{"cell_type":"code","source":["# Pass the numerical features to the downstream_classification function\n","acc, f1 = downstream_classification(X_train_features, y_train_labels_for_clf)\n","print(\"Final Accuracy:\", acc)\n","print(\"Final Macro F1:\", f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAiEU4HdciBb","executionInfo":{"status":"ok","timestamp":1772124594445,"user_tz":-330,"elapsed":33270,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}},"outputId":"e5ec3fd3-6571-4935-f9b4-277a1522a069"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.5603181617322138\n","Macro F1: 0.5518971605268959\n","Final Accuracy: 0.5603181617322138\n","Final Macro F1: 0.5518971605268959\n"]}]},{"cell_type":"markdown","source":["> ### Final Testing Wrapper"],"metadata":{"id":"NZRnInP1d00m"}},{"cell_type":"code","source":["def testing(model_name, tokenized_docs=None, labels=None, dim=100):\n","\n","    wv = load_model(model_name)\n","\n","    print(f\"\\n===== Testing {model_name} =====\")\n","\n","    # Intrinsic\n","    word_similarity_test(wv)\n","    analogy_test(wv)\n","    oov_test(wv, model_name)\n","\n","    # Extrinsic (classification)\n","    if tokenized_docs is not None and labels is not None:\n","\n","        X, y = build_features(tokenized_docs, labels, wv, dim)\n","        downstream_classification(X, y)"],"metadata":{"id":"z_abWWJfdywx","executionInfo":{"status":"ok","timestamp":1772125129810,"user_tz":-330,"elapsed":43,"user":{"displayName":"Kamal Pandey","userId":"03365196632455520767"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["testing(\n","    model_name=\"word2vec-cbow\",\n","    tokenized_docs=final_docs,\n","    labels=labels,\n","    dim=100\n",")"],"metadata":{"id":"MKHxKgPmgAIE"},"execution_count":null,"outputs":[]}]}